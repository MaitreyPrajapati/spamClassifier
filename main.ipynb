{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "VOCAB_SIZE = 400001\n",
    "DIMENSION = 50\n",
    "\n",
    "emb_dict = {}\n",
    "word_to_index = {}\n",
    "embedding_array = np.zeros((VOCAB_SIZE, DIMENSION), dtype='float32')\n",
    "\n",
    "file_path = 'Embeddings/glove.6B/'\n",
    "file_name = 'glove.6B.50d.txt'\n",
    "file = io.open(file_path + file_name, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "\n",
    "\n",
    "index = 0\n",
    "\n",
    "for line in file:\n",
    "    word, vector = line.split(' ', 1)\n",
    "    vector = list(map(float, vector.split(' ')))\n",
    "    \n",
    "    word_to_index[word.lower()] = index\n",
    "    embedding_array[index, :] = vector\n",
    "    \n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing, Splitting and creating TF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'Data/data.csv'\n",
    "\n",
    "all_data = pd.read_csv(dataPath)\n",
    "all_data['Category'] = pd.get_dummies(all_data['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_length(all_sentences):\n",
    "    max_len = 0\n",
    "    mi = 0\n",
    "    index = 0\n",
    "    for sentence in all_sentences:\n",
    "        max_len = max(len(sentence.split(' ')), max_len)\n",
    "        if(max_len == len(sentence.split(' '))):\n",
    "            mi = index\n",
    "        index+=1\n",
    "    return max_len\n",
    "\n",
    "def sentences_to_indices(m, max_len, sentences, word_to_index):\n",
    "    input_array = np.zeros((m, max_len))\n",
    "    sentence_index = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = sentence.lower().split(' ')\n",
    "        words = np.array(list(map(lambda i : word_to_index[i] if i in word_to_index else word_to_index['unk'], words)))\n",
    "        words = np.pad(words, (0, max_len-words.shape[0]), constant_values = (0.))\n",
    "        \n",
    "        input_array[sentence_index, :] = words\n",
    "        sentence_index+=1\n",
    "    return input_array\n",
    "            \n",
    "\n",
    "def get_embedding_matrix():\n",
    "    return embedding_array\n",
    "\n",
    "def get_max_len():\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = all_data['Message']\n",
    "max_len = find_max_length(sentences)\n",
    "\n",
    "m = all_data.shape[0]\n",
    "\n",
    "input_array = sentences_to_indices(m, max_len, sentences, word_to_index)\n",
    "labels = all_data['Category'].to_numpy().reshape(m, 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(input_array, labels, test_size=0.1)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, Y_train.values))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test.values, Y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 171)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Model():\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.max_len = get_max_len()\n",
    "\n",
    "        \n",
    "        self.input_layer = keras.layers.Input(shape = (max_len), name='inputLayer')\n",
    "        \n",
    "        self.embed_layer = self.get_embedding_layer()\n",
    "        self.embedded_layer = self.embed_layer(self.input_layer)\n",
    "        \n",
    "        self.lstm1 = keras.layers.LSTM(128, return_sequences=True, name='lstm1')(self.embedded_layer)\n",
    "#         self.dropout1 = keras.layers.Dropout(rate=0.5, name='dropout1')(self.lstm1)\n",
    "        \n",
    "        self.lstm2 = keras.layers.LSTM(128, name='lstm2')(self.lstm1)\n",
    "        self.dropout2 = keras.layers.Dropout(rate=0.5, name='dropout2')(self.lstm2)\n",
    "        \n",
    "        self.dense1 = keras.layers.Dense(5, name='dense1', activation='relu')(self.dropout2)\n",
    "        self.dense2 = keras.layers.Dense(1, name='dense2', activation='relu')(self.dense1)\n",
    "        \n",
    "        self.sigmoid = keras.layers.Activation(activation='sigmoid', name='sigmoidLayer')(self.dense2)\n",
    "        \n",
    "        self.model = keras.Model(inputs = [self.input_layer], outputs=[self.sigmoid], name='whole_model')\n",
    "        \n",
    "        self.model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07), metrics=['accuracy'])\n",
    "    \n",
    "    def get_embedding_layer(self):\n",
    "        emb = keras.layers.Embedding(VOCAB_SIZE, 50, trainable=False, name='embedLayer')\n",
    "        emb.build((None,))\n",
    "        emb.set_weights([get_embedding_matrix()])\n",
    "        return emb\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def run(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    \n",
    "class AccuracyHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.loss_ = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.loss_.append(logs.get('loss'))\n",
    "\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_Model()\n",
    "model = model.get_model()\n",
    "history = AccuracyHistory()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.4043 - accuracy: 0.8640\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.3990 - accuracy: 0.8670\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.3989 - accuracy: 0.8670\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.3991 - accuracy: 0.8670\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3955 - accuracy: 0.8670\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3962 - accuracy: 0.8670\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3958 - accuracy: 0.8670\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.3963 - accuracy: 0.8670\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3946 - accuracy: 0.8670\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.3945 - accuracy: 0.8670\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3935 - accuracy: 0.8670\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3951 - accuracy: 0.8670\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3930 - accuracy: 0.8670\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3926 - accuracy: 0.8670\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.3936 - accuracy: 0.8670\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3942 - accuracy: 0.8670\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3930 - accuracy: 0.8670\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3934 - accuracy: 0.8670\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3932 - accuracy: 0.8670\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3927 - accuracy: 0.8670\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.3924 - accuracy: 0.8670\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.3929 - accuracy: 0.8670\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3926 - accuracy: 0.8670\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3923 - accuracy: 0.8670\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3928 - accuracy: 0.8670\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3926 - accuracy: 0.8670\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.3923 - accuracy: 0.8670\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.3923 - accuracy: 0.8670\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.3923 - accuracy: 0.8670\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3922 - accuracy: 0.8670\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.3925 - accuracy: 0.8670\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3924 - accuracy: 0.8670\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3922 - accuracy: 0.8670\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3924 - accuracy: 0.8670\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3923 - accuracy: 0.8670\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.3922 - accuracy: 0.8670\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.3924 - accuracy: 0.8670\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.3923 - accuracy: 0.8670\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3922 - accuracy: 0.8670\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.3924 - accuracy: 0.8670\n",
      "Epoch 41/100\n",
      " 79/157 [==============>...............] - ETA: 13s - loss: 0.3696 - accuracy: 0.8790"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, callbacks=[history], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
